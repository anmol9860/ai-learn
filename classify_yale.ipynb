{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anmol9860/ai-learn/blob/main/classify_yale.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XEb0VDGENcut"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rTTlohXBNXfP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671f0ec6-8d6b-4c95-ed9b-94d79b9f88ab"
      },
      "source": [
        "from google.colab import drive # mounts the google drive for a new notebook \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nygdl2G9Nieo"
      },
      "source": [
        "# load the 2 npy files created by the process_yale_images.ipynb \n",
        "from numpy import load\n",
        "import numpy as np\n",
        "path = '/content/drive/My Drive/'\n",
        "# load array\n",
        "y = load(path + 'yaleExtB_target.npy')\n",
        "X = load(path + 'yaleExtB_data.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Th62dSshOXqa"
      },
      "source": [
        "from sklearn.model_selection import train_test_split # loads functions from the ML library sklearn \n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.neural_network import MLPClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uz5JnDUOOgEw"
      },
      "source": [
        "# split into a training and testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I3HtYdw6Oj6J"
      },
      "source": [
        "# PCA \n",
        "nof_prin_components = 200  # PARAMETER for optimisation in expereiments\n",
        "pca = PCA(n_components=nof_prin_components, whiten=True).fit(X_train)\n",
        "# applies PCA to the train and test images to calculate the principal components\n",
        "X_train_pca = pca.transform(X_train) \n",
        "X_test_pca = pca.transform(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4PyCqp6PwDl"
      },
      "source": [
        "[Documentation of ML sklearn library](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZ3tZ3u9On_z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343d3379-4bb8-4ac5-8e8c-f821068a5c1b"
      },
      "source": [
        "# train a neural network\n",
        "nohn = 200 # nof hidden neurons\n",
        "print(\"Fitting the classifier to the training set\")\n",
        "clf = MLPClassifier(hidden_layer_sizes=(nohn,), solver='sgd', activation='tanh', batch_size=256, verbose=True, early_stopping=True).fit(X_train_pca, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting the classifier to the training set\n",
            "Iteration 1, loss = 3.66362713\n",
            "Validation score: 0.041667\n",
            "Iteration 2, loss = 3.64113375\n",
            "Validation score: 0.041667\n",
            "Iteration 3, loss = 3.60697898\n",
            "Validation score: 0.041667\n",
            "Iteration 4, loss = 3.56608143\n",
            "Validation score: 0.041667\n",
            "Iteration 5, loss = 3.52137744\n",
            "Validation score: 0.058333\n",
            "Iteration 6, loss = 3.47455752\n",
            "Validation score: 0.075000\n",
            "Iteration 7, loss = 3.42642654\n",
            "Validation score: 0.083333\n",
            "Iteration 8, loss = 3.37796598\n",
            "Validation score: 0.091667\n",
            "Iteration 9, loss = 3.32902684\n",
            "Validation score: 0.100000\n",
            "Iteration 10, loss = 3.28041775\n",
            "Validation score: 0.100000\n",
            "Iteration 11, loss = 3.23193132\n",
            "Validation score: 0.108333\n",
            "Iteration 12, loss = 3.18398648\n",
            "Validation score: 0.108333\n",
            "Iteration 13, loss = 3.13624284\n",
            "Validation score: 0.133333\n",
            "Iteration 14, loss = 3.08885473\n",
            "Validation score: 0.141667\n",
            "Iteration 15, loss = 3.04159458\n",
            "Validation score: 0.183333\n",
            "Iteration 16, loss = 2.99508948\n",
            "Validation score: 0.200000\n",
            "Iteration 17, loss = 2.94857373\n",
            "Validation score: 0.208333\n",
            "Iteration 18, loss = 2.90290521\n",
            "Validation score: 0.208333\n",
            "Iteration 19, loss = 2.85764406\n",
            "Validation score: 0.208333\n",
            "Iteration 20, loss = 2.81289633\n",
            "Validation score: 0.225000\n",
            "Iteration 21, loss = 2.76862396\n",
            "Validation score: 0.225000\n",
            "Iteration 22, loss = 2.72492947\n",
            "Validation score: 0.225000\n",
            "Iteration 23, loss = 2.68148112\n",
            "Validation score: 0.266667\n",
            "Iteration 24, loss = 2.63834992\n",
            "Validation score: 0.291667\n",
            "Iteration 25, loss = 2.59582161\n",
            "Validation score: 0.308333\n",
            "Iteration 26, loss = 2.55370026\n",
            "Validation score: 0.350000\n",
            "Iteration 27, loss = 2.51210419\n",
            "Validation score: 0.350000\n",
            "Iteration 28, loss = 2.47115742\n",
            "Validation score: 0.383333\n",
            "Iteration 29, loss = 2.43040662\n",
            "Validation score: 0.383333\n",
            "Iteration 30, loss = 2.39027755\n",
            "Validation score: 0.408333\n",
            "Iteration 31, loss = 2.35051386\n",
            "Validation score: 0.416667\n",
            "Iteration 32, loss = 2.31129081\n",
            "Validation score: 0.425000\n",
            "Iteration 33, loss = 2.27275893\n",
            "Validation score: 0.441667\n",
            "Iteration 34, loss = 2.23460358\n",
            "Validation score: 0.458333\n",
            "Iteration 35, loss = 2.19697176\n",
            "Validation score: 0.475000\n",
            "Iteration 36, loss = 2.15995149\n",
            "Validation score: 0.483333\n",
            "Iteration 37, loss = 2.12362031\n",
            "Validation score: 0.500000\n",
            "Iteration 38, loss = 2.08763780\n",
            "Validation score: 0.500000\n",
            "Iteration 39, loss = 2.05218412\n",
            "Validation score: 0.500000\n",
            "Iteration 40, loss = 2.01738604\n",
            "Validation score: 0.508333\n",
            "Iteration 41, loss = 1.98305205\n",
            "Validation score: 0.525000\n",
            "Iteration 42, loss = 1.94971796\n",
            "Validation score: 0.533333\n",
            "Iteration 43, loss = 1.91680055\n",
            "Validation score: 0.533333\n",
            "Iteration 44, loss = 1.88440002\n",
            "Validation score: 0.541667\n",
            "Iteration 45, loss = 1.85253707\n",
            "Validation score: 0.541667\n",
            "Iteration 46, loss = 1.82128390\n",
            "Validation score: 0.541667\n",
            "Iteration 47, loss = 1.79056435\n",
            "Validation score: 0.541667\n",
            "Iteration 48, loss = 1.76024467\n",
            "Validation score: 0.550000\n",
            "Iteration 49, loss = 1.73060785\n",
            "Validation score: 0.566667\n",
            "Iteration 50, loss = 1.70152002\n",
            "Validation score: 0.566667\n",
            "Iteration 51, loss = 1.67299437\n",
            "Validation score: 0.566667\n",
            "Iteration 52, loss = 1.64492525\n",
            "Validation score: 0.566667\n",
            "Iteration 53, loss = 1.61738206\n",
            "Validation score: 0.583333\n",
            "Iteration 54, loss = 1.59030129\n",
            "Validation score: 0.600000\n",
            "Iteration 55, loss = 1.56377166\n",
            "Validation score: 0.608333\n",
            "Iteration 56, loss = 1.53769472\n",
            "Validation score: 0.616667\n",
            "Iteration 57, loss = 1.51214569\n",
            "Validation score: 0.616667\n",
            "Iteration 58, loss = 1.48688541\n",
            "Validation score: 0.625000\n",
            "Iteration 59, loss = 1.46217424\n",
            "Validation score: 0.633333\n",
            "Iteration 60, loss = 1.43786351\n",
            "Validation score: 0.633333\n",
            "Iteration 61, loss = 1.41400950\n",
            "Validation score: 0.641667\n",
            "Iteration 62, loss = 1.39078886\n",
            "Validation score: 0.641667\n",
            "Iteration 63, loss = 1.36795333\n",
            "Validation score: 0.650000\n",
            "Iteration 64, loss = 1.34556250\n",
            "Validation score: 0.658333\n",
            "Iteration 65, loss = 1.32354380\n",
            "Validation score: 0.666667\n",
            "Iteration 66, loss = 1.30197390\n",
            "Validation score: 0.675000\n",
            "Iteration 67, loss = 1.28083490\n",
            "Validation score: 0.683333\n",
            "Iteration 68, loss = 1.25995830\n",
            "Validation score: 0.700000\n",
            "Iteration 69, loss = 1.23971596\n",
            "Validation score: 0.700000\n",
            "Iteration 70, loss = 1.21984825\n",
            "Validation score: 0.716667\n",
            "Iteration 71, loss = 1.20033937\n",
            "Validation score: 0.725000\n",
            "Iteration 72, loss = 1.18115606\n",
            "Validation score: 0.725000\n",
            "Iteration 73, loss = 1.16244469\n",
            "Validation score: 0.725000\n",
            "Iteration 74, loss = 1.14403578\n",
            "Validation score: 0.725000\n",
            "Iteration 75, loss = 1.12587437\n",
            "Validation score: 0.725000\n",
            "Iteration 76, loss = 1.10822845\n",
            "Validation score: 0.733333\n",
            "Iteration 77, loss = 1.09075053\n",
            "Validation score: 0.741667\n",
            "Iteration 78, loss = 1.07387455\n",
            "Validation score: 0.741667\n",
            "Iteration 79, loss = 1.05717180\n",
            "Validation score: 0.741667\n",
            "Iteration 80, loss = 1.04090205\n",
            "Validation score: 0.750000\n",
            "Iteration 81, loss = 1.02505890\n",
            "Validation score: 0.750000\n",
            "Iteration 82, loss = 1.00952297\n",
            "Validation score: 0.750000\n",
            "Iteration 83, loss = 0.99414514\n",
            "Validation score: 0.758333\n",
            "Iteration 84, loss = 0.97904877\n",
            "Validation score: 0.758333\n",
            "Iteration 85, loss = 0.96431617\n",
            "Validation score: 0.758333\n",
            "Iteration 86, loss = 0.94998182\n",
            "Validation score: 0.758333\n",
            "Iteration 87, loss = 0.93585257\n",
            "Validation score: 0.758333\n",
            "Iteration 88, loss = 0.92187037\n",
            "Validation score: 0.758333\n",
            "Iteration 89, loss = 0.90837294\n",
            "Validation score: 0.758333\n",
            "Iteration 90, loss = 0.89512465\n",
            "Validation score: 0.758333\n",
            "Iteration 91, loss = 0.88204733\n",
            "Validation score: 0.758333\n",
            "Iteration 92, loss = 0.86930143\n",
            "Validation score: 0.766667\n",
            "Iteration 93, loss = 0.85679478\n",
            "Validation score: 0.775000\n",
            "Iteration 94, loss = 0.84439584\n",
            "Validation score: 0.775000\n",
            "Iteration 95, loss = 0.83231746\n",
            "Validation score: 0.775000\n",
            "Iteration 96, loss = 0.82040672\n",
            "Validation score: 0.775000\n",
            "Iteration 97, loss = 0.80885220\n",
            "Validation score: 0.783333\n",
            "Iteration 98, loss = 0.79745132\n",
            "Validation score: 0.783333\n",
            "Iteration 99, loss = 0.78629453\n",
            "Validation score: 0.791667\n",
            "Iteration 100, loss = 0.77531942\n",
            "Validation score: 0.791667\n",
            "Iteration 101, loss = 0.76460646\n",
            "Validation score: 0.791667\n",
            "Iteration 102, loss = 0.75391279\n",
            "Validation score: 0.791667\n",
            "Iteration 103, loss = 0.74348807\n",
            "Validation score: 0.791667\n",
            "Iteration 104, loss = 0.73311014\n",
            "Validation score: 0.791667\n",
            "Iteration 105, loss = 0.72308221\n",
            "Validation score: 0.808333\n",
            "Iteration 106, loss = 0.71321482\n",
            "Validation score: 0.808333\n",
            "Iteration 107, loss = 0.70359249\n",
            "Validation score: 0.808333\n",
            "Iteration 108, loss = 0.69401774\n",
            "Validation score: 0.808333\n",
            "Iteration 109, loss = 0.68466574\n",
            "Validation score: 0.808333\n",
            "Iteration 110, loss = 0.67542793\n",
            "Validation score: 0.808333\n",
            "Iteration 111, loss = 0.66639678\n",
            "Validation score: 0.808333\n",
            "Iteration 112, loss = 0.65757406\n",
            "Validation score: 0.808333\n",
            "Iteration 113, loss = 0.64903889\n",
            "Validation score: 0.808333\n",
            "Iteration 114, loss = 0.64069470\n",
            "Validation score: 0.808333\n",
            "Iteration 115, loss = 0.63238331\n",
            "Validation score: 0.808333\n",
            "Iteration 116, loss = 0.62431343\n",
            "Validation score: 0.808333\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GpQlLK8wO-lw",
        "outputId": "757faaec-f76b-46a3-cc04-d6041dfa5fbd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y_pred = clf.predict(X_test_pca) # reoognises the test images \n",
        "print(classification_report(y_test, y_pred)) # the recognition accuracy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         2.0       0.62      0.83      0.71         6\n",
            "         3.0       0.80      0.80      0.80         5\n",
            "         4.0       1.00      0.78      0.88         9\n",
            "         5.0       0.91      1.00      0.95        10\n",
            "         6.0       1.00      0.70      0.82        10\n",
            "         7.0       0.62      1.00      0.77        10\n",
            "         8.0       0.86      0.86      0.86         7\n",
            "         9.0       0.67      1.00      0.80         2\n",
            "        11.0       0.89      0.89      0.89         9\n",
            "        12.0       0.89      1.00      0.94         8\n",
            "        13.0       0.85      0.79      0.81        14\n",
            "        15.0       0.90      0.75      0.82        12\n",
            "        16.0       0.86      0.86      0.86         7\n",
            "        17.0       0.75      0.75      0.75         8\n",
            "        18.0       0.86      1.00      0.92        12\n",
            "        20.0       1.00      0.67      0.80        12\n",
            "        22.0       0.83      0.83      0.83        12\n",
            "        23.0       0.93      0.74      0.82        19\n",
            "        24.0       1.00      0.94      0.97        17\n",
            "        25.0       0.75      0.90      0.82        10\n",
            "        26.0       0.79      0.92      0.85        12\n",
            "        27.0       0.88      0.88      0.88         8\n",
            "        28.0       1.00      0.93      0.96        14\n",
            "        32.0       0.86      0.92      0.89        13\n",
            "        33.0       0.86      0.75      0.80         8\n",
            "        34.0       1.00      0.78      0.88         9\n",
            "        35.0       0.73      0.89      0.80         9\n",
            "        37.0       0.89      1.00      0.94         8\n",
            "        38.0       1.00      1.00      1.00        10\n",
            "        39.0       1.00      1.00      1.00        10\n",
            "\n",
            "    accuracy                           0.87       300\n",
            "   macro avg       0.87      0.87      0.86       300\n",
            "weighted avg       0.88      0.87      0.87       300\n",
            "\n"
          ]
        }
      ]
    }
  ]
}